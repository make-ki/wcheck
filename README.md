# wcheck

*readme generated by Claude Opus 4.5*

---

*so you wanna check if a million websites are up or down without clicking through each one like a maniac? same. that's why this exists.*

*wcheck is a dead simple, concurrent website availability checker written in Go. point it at a list of URLs and let it rip.*

---

## *what does it do?*

*takes a file full of URLs, spins up a bunch of goroutines (workers), and hammers through them to tell you which ones are [UP] and which ones are [DOWN]. that's it. no fancy dashboards, no databases, just stdout and vibes.*

---

## *specs & tech*

| *thing* | *details* |
|---------|-----------|
| *language* | Go 1.25.5 |
| *concurrency model* | goroutines + channels + sync.WaitGroup |
| *http client* | standard library `net/http` with 10s timeout |
| *url validation* | regex-based filtering |
| *graceful shutdown* | catches SIGINT (Ctrl+C) and prints stats before dying |
| *user-agent* | `wcheck/1.0 (Language=Go)` |
| *considers "UP"* | HTTP status codes 200-420 |

---

## *getting it*

```bash
# clone it
git clone https://github.com/make-ki/wcheck.git
cd wcheck

# build it
go build -o wcheck .

# or just run it directly
go run main.go -w yourlist.txt -n 100
```

---

## *usage*

```bash
./wcheck -w <path-to-url-list> -n <number-of-workers>
```

| *flag* | *default* | *what it does* |
|--------|-----------|----------------|
| `-w` | `./majestic` | *path to your wordlist/url file* |
| `-n` | `10` | *number of concurrent workers (goroutines)* |

### *example*

```bash
./wcheck -w urls.txt -n 500
```

---

## *⚠️ warnings & things you should know*

### *about the `-n` flag*

*look, goroutines are cheap. Go can handle 10k+ of them no problem. your system won't explode from that.*

***BUT*** *here's the thing - network I/O is the real bottleneck. cranking `-n` up to 50,000 doesn't mean you'll check 50,000 sites in parallel. your network stack, your ISP, DNS resolution, and the poor websites on the receiving end all have limits. you'll probably just end up with a bunch of timeouts and connection refused errors.*

*start with something reasonable like 100-500 and see how your network handles it. if things are smooth, bump it up gradually.*

---

### *about the `majestic` file*

*that file in the repo? it's just there as a placeholder/example to represent what a potential URL list might look like. it contains real domains.*

***please do NOT actually use it for testing.***

*those are real websites run by real people. the wikipedia folks especially - they're nice people maintaining free knowledge for humanity. they don't deserve your testing traffic. find some domains you own or use something like `httpbin.org` for testing.*

*i am NOT responsible if you go full send on random domains and get your IP banned or angry emails from sysadmins.*

---

### *format your url list properly!!*

*your wordlist should have ONE url per line. no schemes needed (the tool adds `https://` automatically). no trailing garbage. no blank lines with invisible spaces. no windows CRLF nonsense if you're on linux.*

*good:*
```
example.com
subdomain.example.org
another-site.net/path
```

*bad:*
```
https://example.com     <- don't include the scheme
example.com, another.com  <- one per line buddy
   example.com    <- trim your whitespace

                  <- empty lines = problems
```

*if your list is messy, you'll get a wall of errors and wonder why nothing works. clean your data first.*

---

## *output*

*pretty straightforward:*

```
[UP 200] example.com
[DOWN -1] doesnt-exist-lmao.xyz
[UP 301] redirecting-site.com
```

*-1 means the request failed entirely (timeout, DNS failure, connection refused, etc.)*

*hit Ctrl+C anytime to stop and see your current UP/DOWN count.*

---

## *license*

*do whatever you want with it honestly*

---

*happy checking ✨*
